#!/bin/bash

# DataVault CLI KullanÄ±m Ã–rnekleri
# Bu script tÃ¼m temel CLI komutlarÄ±nÄ± demonstre eder

echo "ğŸš€ DataVault CLI Ã–rnekleri - BaÅŸlatÄ±lÄ±yor..."

# Renk kodlarÄ±
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Ã–rnek dosyalar oluÅŸtur
echo -e "${BLUE}ğŸ“ Ã–rnek dosyalar oluÅŸturuluyor...${NC}"
mkdir -p example-data
echo '{"model": "mnist_classifier", "accuracy": 0.98, "epochs": 50}' > example-data/model_info.json
echo '{"training_data": "mnist", "batch_size": 32, "learning_rate": 0.001}' > example-data/training_config.json
dd if=/dev/urandom of=example-data/model.pt bs=1024 count=10 2>/dev/null
echo "Example dataset content" > example-data/dataset.txt

echo -e "\n${GREEN}âœ… Ã–rnek dosyalar hazÄ±rlandÄ±!${NC}"

# 1. Dosya YÃ¼kleme Ã–rnekleri
echo -e "\n${BLUE}ğŸ“¤ 1. DOSYA YÃœKLEME Ã–RNEKLERÄ°${NC}"

echo -e "\n${YELLOW}ğŸ¤– PyTorch Model YÃ¼kleme:${NC}"
echo "bun run upload -- -f ./example-data/model.pt -a ml-training -n mnist-classifier -s production -v 1.0.0 -o team@example.com --receipt"

echo -e "\n${YELLOW}ğŸ“Š Veri Seti YÃ¼kleme:${NC}"
echo "bun run upload -- -f ./example-data/dataset.txt -a data-pipeline -n customer-data -s train -v 1.0.0 -o data-team@example.com --receipt"

echo -e "\n${YELLOW}âš™ï¸ Konfigurasyon DosyasÄ± YÃ¼kleme:${NC}"
echo "bun run upload -- -f ./example-data/training_config.json -a ml-training -n training-config -s production -v 1.0.0 -o ml-engineer@example.com --receipt"

echo -e "\n${YELLOW}ğŸ“‹ Model Bilgileri YÃ¼kleme:${NC}"
echo "bun run upload -- -f ./example-data/model_info.json -a ml-training -n model-metadata -s production -v 1.0.0 -o ml-engineer@example.com --receipt"

# 2. Sorgulama Ã–rnekleri
echo -e "\n${BLUE}ğŸ” 2. SORGULAMA Ã–RNEKLERÄ°${NC}"

echo -e "\n${YELLOW}ğŸ¯ Belirli veri seti arama:${NC}"
echo "bun run query -- -n mnist-classifier -l 10"

echo -e "\n${YELLOW}ğŸ“± Uygulama bazlÄ± arama:${NC}"
echo "bun run query -- -a ml-training -l 20"

echo -e "\n${YELLOW}ğŸ‘¤ Sahip bazlÄ± arama:${NC}"
echo "bun run query -- -o team@example.com -l 15"

echo -e "\n${YELLOW}ğŸ—‚ï¸ Split bazlÄ± arama:${NC}"
echo "bun run query -- -s production -l 10"

echo -e "\n${YELLOW}ğŸ“… Tarih aralÄ±ÄŸÄ±nda arama:${NC}"
echo "bun run query -- --start-time 2024-01-01T00:00:00Z --end-time 2024-12-31T23:59:59Z -l 20"

echo -e "\n${YELLOW}ğŸ”„ KarmaÅŸÄ±k filtreleme:${NC}"
echo "bun run query -- -n mnist-classifier -s production -a ml-training -o team@example.com -l 5"

# 3. Dosya Ä°ndirme Ã–rnekleri
echo -e "\n${BLUE}ğŸ“¥ 3. DOSYA Ä°NDÄ°RME Ã–RNEKLERÄ°${NC}"

echo -e "\n${YELLOW}â¬‡ï¸ Transaction ID ile indirme:${NC}"
echo "bun run fetch -- -i <TRANSACTION_ID> -o ./downloads/"

echo -e "\n${YELLOW}ğŸ”„ Ãœzerine yazma ile indirme:${NC}"
echo "bun run fetch -- -i <TRANSACTION_ID> -o ./downloads/model.pt --overwrite"

# 4. SÃ¼rÃ¼m YÃ¶netimi Ã–rnekleri
echo -e "\n${BLUE}ğŸ“‹ 4. SÃœRÃœM YÃ–NETÄ°MÄ° Ã–RNEKLERÄ°${NC}"

echo -e "\n${YELLOW}ğŸ†• En son sÃ¼rÃ¼mÃ¼ getirme:${NC}"
echo "bun run latest -- -n mnist-classifier -s production"

echo -e "\n${YELLOW}ğŸ” Belirli split'in en son sÃ¼rÃ¼mÃ¼:${NC}"
echo "bun run latest -- -n customer-data -s train"

# 5. Hesap YÃ¶netimi
echo -e "\n${BLUE}ğŸ’° 5. HESAP YÃ–NETÄ°MÄ°${NC}"

echo -e "\n${YELLOW}ğŸ’³ Hesap bakiyesi kontrol:${NC}"
echo "bun run balance"

# 6. GeliÅŸmiÅŸ KullanÄ±m SenaryolarÄ±
echo -e "\n${BLUE}ğŸš€ 6. GELÄ°ÅMÄ°Å KULLANIM SENARYOLARI${NC}"

echo -e "\n${YELLOW}ğŸ”„ Model pipeline workflow:${NC}"
cat << 'EOF'
# 1. Model eÄŸitimi sonrasÄ± checkpoint yÃ¼kle
bun run upload -- -f ./models/checkpoint_epoch_50.pt -a ml-pipeline -n mnist-v2 -s checkpoint -v 1.1.0 -o trainer@example.com --receipt

# 2. En son checkpoint'i bul
bun run latest -- -n mnist-v2 -s checkpoint

# 3. Production'a terfi ettir
bun run upload -- -f ./models/final_model.pt -a ml-pipeline -n mnist-v2 -s production -v 1.1.0 -o mlops@example.com --receipt

# 4. Production modelini doÄŸrula
bun run query -- -n mnist-v2 -s production -v 1.1.0
EOF

echo -e "\n${YELLOW}ğŸ“Š Veri seti management workflow:${NC}"
cat << 'EOF'
# 1. Ham veriyi yÃ¼kle
bun run upload -- -f ./data/raw_data.csv -a data-processing -n customer-analytics -s raw -v 1.0.0 -o data-engineer@example.com --receipt

# 2. Ä°ÅŸlenmiÅŸ veriyi yÃ¼kle
bun run upload -- -f ./data/processed_features.csv -a data-processing -n customer-analytics -s processed -v 1.0.0 -o data-engineer@example.com --receipt

# 3. Train/test split'lerini yÃ¼kle
bun run upload -- -f ./data/train_set.csv -a ml-ready -n customer-analytics -s train -v 1.0.0 -o ml-team@example.com --receipt
bun run upload -- -f ./data/test_set.csv -a ml-ready -n customer-analytics -s test -v 1.0.0 -o ml-team@example.com --receipt
EOF

# 7. Ä°zleme ve Audit
echo -e "\n${YELLOW}ğŸ“ˆ Ä°zleme ve audit workflow:${NC}"
cat << 'EOF'
# 1. GÃ¼nlÃ¼k model performansÄ±nÄ± kaydet
bun run upload -- -f ./metrics/daily_metrics.json -a monitoring -n model-performance -s daily -v $(date +%Y.%m.%d) -o monitor@example.com --receipt

# 2. Son 30 gÃ¼nÃ¼n metriklerini listele
bun run query -- -n model-performance -s daily --start-time $(date -d '30 days ago' -Iseconds) -l 30

# 3. Audit log'larÄ±nÄ± kaydet
bun run upload -- -f ./logs/audit_$(date +%Y%m%d).log -a audit -n system-audit -s daily -v $(date +%Y.%m.%d) -o security@example.com --receipt
EOF

# Temizlik uyarÄ±sÄ±
echo -e "\n${RED}ğŸ§¹ Temizlik:${NC}"
echo "rm -rf example-data"

echo -e "\n${GREEN}âœ… TÃ¼m CLI Ã¶rnekleri listelendi!${NC}"
echo -e "${BLUE}ğŸ’¡ Bu komutlarÄ± Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce .env dosyasÄ±nÄ± doÄŸru ÅŸekilde yapÄ±landÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun.${NC}"

# Ã–rnek dosyalarÄ± temizle
echo -e "\n${YELLOW}ğŸ§¹ Ã–rnek dosyalar temizleniyor...${NC}"
rm -rf example-data

echo -e "${GREEN}âœ… Temizlik tamamlandÄ±!${NC}"